{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiJpPrw7HbA-"
   },
   "source": [
    "# Problem description\n",
    "\n",
    "The problem of interest is the prediction of apply rate. Imagine a user visiting a website, and performing a job search. From the set of displayed results, user clicks on certain ones that she is interested in, and after checking job descriptions, she further clicks on apply button therein to land in to an application page. The apply rate is defined as the fraction of applies (after visiting job description pages), and the goal is to predict this metric using the dataset described in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1iTvcOSJiJB"
   },
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AkDygRACJLAC"
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "X5gl76G3GXzF",
    "outputId": "8bd13b46-bc10-4c88-c3f6-3ca7d9c7aeb9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Apply_Rate_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJQL5dvqKjll"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGkqut6uOEFv"
   },
   "source": [
    "Each row in the dataset corresponds to a user’s view of a job listing. It has 10 columns as described below.\n",
    "\n",
    "1. title proximity tfidf: Measures the closeness of query and job title.\n",
    "2. description proximity tfidf: Measures the closeness of query and job description.\n",
    "3. main query tfidf: A score related to user query closeness to job title and job description.\n",
    "4. query jl score: Measures the popularity of query and job listing pair.\n",
    "5. query title score: Measures the popularity of query and job title pair.\n",
    "6. city match: Indicates if the job listing matches to user (or, user-specified) location.\n",
    "7. job age days: Indicates the age of job listing posted.\n",
    "8. apply: Indicates if the user has applied for this job listing.\n",
    "9. search date pacific: Date of the activity.\n",
    "10. class id: Class ID of the job title clicked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5CmiJ5-O7r3"
   },
   "source": [
    "There are two parts to the problem.\n",
    "\n",
    ". We have to only focus on the first 7 columns and use these as features to predict how many users apply to the website.\n",
    "\n",
    ". We have to consider adding the last column to the feature set (“class id”) and check if the classification performance increases or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8JXf7YIJQOq"
   },
   "source": [
    "##Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glPL6LQKJIuI"
   },
   "outputs": [],
   "source": [
    "# Check the total number of observations in the dataset\n",
    "\n",
    "print('Total number of observations in the dataset are:', df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uldU10_dO4ul"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqYwSWVsS31G"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "1. title_proximity_tfidf, description_proximity_tfidf and city_match contains null values\n",
    "2. There are 7 float type, 2 integer type and 1 object type features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeFZqMbbTt16"
   },
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "\n",
    "df.drop(['apply'],axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWADxp0LVirq"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "1. There is notably a large difference between 75th %tile and max values of mostly all the predictors.\n",
    "2. Median value of ‘title_proximity_tfidf’, ‘description_proximity_tfidf’, ‘main_query_tfidf’, ‘query_jl_score’, ‘query_title_score’, ‘job_age_days’ is lower than mean\n",
    "3. Thus observation 1 and 2 suggest there are lot of outliers in the dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwTzj4xZVgBH"
   },
   "outputs": [],
   "source": [
    "# Lets check the distribution for classes who applied and did not apply\n",
    "\n",
    "count_classes = pd.value_counts(df['apply'], sort = True)\n",
    "count_classes.plot(kind = 'bar')\n",
    "\n",
    "plt.title(\"Apply Rate\")\n",
    "plt.xticks(range(2))\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "print('Number of customers who didnt apply:',df['apply'].value_counts()[0])\n",
    "print('Number of customers who applied:',df['apply'].value_counts()[1])\n",
    "print('Percentage of apply to non apply',df['apply'].value_counts()[0]/df['apply'].value_counts()[1],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOL6PVOhYg5_"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "The data is imbalanced and so we might have to use techniques like resampling (undersampling or oversampling) or use metrics like AUC-ROC curve or AUPRC or SMOTE to handle imbalanced data. Lets explore further which will help us decide what technique should we use. Note: It is already given in the dataset that I have to use AUC as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSxsVZRqYfDg"
   },
   "outputs": [],
   "source": [
    "# Lets check the correlation between the features\n",
    "\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeKqXd_pZP9g"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "1. title_proximity_tfidf and main_query_tfidf are correlated with value of arounf 0.7\n",
    "2. Other features are not highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FexZUZppZO2A"
   },
   "outputs": [],
   "source": [
    "# Check the outliers\n",
    "\n",
    "l = ['title_proximity_tfidf', 'description_proximity_tfidf',\n",
    "       'main_query_tfidf', 'query_jl_score', 'query_title_score',\n",
    "       'city_match', 'job_age_days']\n",
    "number_of_columns=7\n",
    "number_of_rows = len(l)-1/number_of_columns\n",
    "plt.figure(figsize=(number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.boxplot(df[l[i]],color='green',orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXNgVJk1n1rx"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "As we can see there are lot of outliers in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIjuDkiWnwDD"
   },
   "outputs": [],
   "source": [
    "# Check the distribution\n",
    "\n",
    "# Now to check the linearity of the variables it is a good practice to plot distribution graph and look for skewness \n",
    "# of features. Kernel density estimate (kde) is a quite useful tool for plotting the shape of a distribution.\n",
    "\n",
    "for feature in df.columns[:-2]:\n",
    "    ax = plt.subplot()\n",
    "    sns.distplot(df[df['apply'] == 1][feature], bins=50, label='Anormal')\n",
    "    sns.distplot(df[df['apply'] == 0][feature], bins=50, label='Normal')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('histogram of feature: ' + str(feature))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC_viOtYn_GZ"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "For all the features, both apply and non apply rates have almost similar distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgEO8i-WouWR"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIUg-7jTn023"
   },
   "outputs": [],
   "source": [
    "# Firstly lets drop duplicate entries \n",
    "\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbCj3Ezlp1V2"
   },
   "outputs": [],
   "source": [
    "# Check number of missing values in every columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Mit7jD8qUaT"
   },
   "outputs": [],
   "source": [
    "# Lets check the value counts for the three columns\n",
    "df['title_proximity_tfidf'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VdALrKlqa_U"
   },
   "outputs": [],
   "source": [
    "df['description_proximity_tfidf'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "711i3e2DqjT3"
   },
   "outputs": [],
   "source": [
    "df['city_match'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlS70mbYqv57"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "The first 2 columns contains mostly value zero so it would be a safe option to impute a value of '0' to the first two columns. For the 'city-match' column, lets check the percentage of apply and non apply before and after we remove the NaN values. If the percentage is same, we can conclude that it is safe to remove rows that have NaN values in City_match column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTknm-gzq613"
   },
   "outputs": [],
   "source": [
    "df['title_proximity_tfidf'].fillna(0,inplace=True)\n",
    "df['description_proximity_tfidf'].fillna(0,inplace=True)\n",
    "df.dropna(subset=['city_match'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VYbbAenrCNg"
   },
   "source": [
    "Note: I will not be removing outliers since there is possibility of them carrying important information which can help us detect the apply and non apply cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpPePtu6q_VM"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCoH_nwyCL7Z"
   },
   "outputs": [],
   "source": [
    "# From the correlation graph, we observed that title_proximity_tfidf and main_query_tfidf are quite correlated, \n",
    "# lets merge them and get a single feature by multiplying both of them\n",
    "\n",
    "df['main_title_tfidf'] = df['title_proximity_tfidf']*df['main_query_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFsfYZjLCSPh"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['title_proximity_tfidf','main_query_tfidf'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyY4UoAHPRfl"
   },
   "source": [
    "# Resources\n",
    "\n",
    "[1] https://www.kaggle.com/kerneler/starter-predict-click-through-rate-dcafee5b-2/data\n",
    "\n",
    "[2] https://towardsdatascience.com/predicting-click-through-rate-for-a-website-7cd2a892d26e\n",
    "\n",
    "[3] https://github.com/animeshgoyal9/Predicting-Apply-rate-for-a-job-search-agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1VZRqI6CTk_"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZcWg6DCPh6q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Predict Apply rate for a job search agency.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
